{".class":"MypyFile","_fullname":"vllm.attention.ops.flashmla","future_import_flags":[],"is_partial_stub_package":false,"is_stub":false,"names":{".class":"SymbolTable","Optional":{".class":"SymbolTableNode","cross_ref":"typing.Optional","kind":"Gdef"},"Tuple":{".class":"SymbolTableNode","cross_ref":"typing.Tuple","kind":"Gdef"},"__annotations__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"vllm.attention.ops.flashmla.__annotations__","name":"__annotations__","type":{".class":"Instance","args":["builtins.str",{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.dict"}}},"__doc__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"vllm.attention.ops.flashmla.__doc__","name":"__doc__","type":"builtins.str"}},"__file__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"vllm.attention.ops.flashmla.__file__","name":"__file__","type":"builtins.str"}},"__name__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"vllm.attention.ops.flashmla.__name__","name":"__name__","type":"builtins.str"}},"__package__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"vllm.attention.ops.flashmla.__package__","name":"__package__","type":"builtins.str"}},"__spec__":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready"],"fullname":"vllm.attention.ops.flashmla.__spec__","name":"__spec__","type":"_frozen_importlib.ModuleSpec"}},"_flashmla_C_AVAILABLE":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_ready","is_inferred","has_explicit_value"],"fullname":"vllm.attention.ops.flashmla._flashmla_C_AVAILABLE","name":"_flashmla_C_AVAILABLE","type":"builtins.bool"}},"current_platform":{".class":"SymbolTableNode","cross_ref":"vllm.platforms.current_platform","kind":"Gdef"},"flash_mla_with_kvcache":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0,0,0,0,0,0,1,1],"arg_names":["q","k_cache","block_table","cache_seqlens","head_dim_v","tile_scheduler_metadata","num_splits","softmax_scale","causal"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"vllm.attention.ops.flashmla.flash_mla_with_kvcache","name":"flash_mla_with_kvcache","type":{".class":"CallableType","arg_kinds":[0,0,0,0,0,0,0,1,1],"arg_names":["q","k_cache","block_table","cache_seqlens","head_dim_v","tile_scheduler_metadata","num_splits","softmax_scale","causal"],"arg_types":["torch._tensor.Tensor","torch._tensor.Tensor","torch._tensor.Tensor","torch._tensor.Tensor","builtins.int","torch._tensor.Tensor","torch._tensor.Tensor",{".class":"UnionType","items":["builtins.float",{".class":"NoneType"}],"uses_pep604_syntax":false},"builtins.bool"],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"flash_mla_with_kvcache","ret_type":{".class":"TupleType","implicit":false,"items":["torch._tensor.Tensor","torch._tensor.Tensor"],"partial_fallback":{".class":"Instance","args":[{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.tuple"}},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"get_mla_metadata":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[0,0,0],"arg_names":["cache_seqlens","num_heads_per_head_k","num_heads_k"],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"vllm.attention.ops.flashmla.get_mla_metadata","name":"get_mla_metadata","type":{".class":"CallableType","arg_kinds":[0,0,0],"arg_names":["cache_seqlens","num_heads_per_head_k","num_heads_k"],"arg_types":["torch._tensor.Tensor","builtins.int","builtins.int"],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"get_mla_metadata","ret_type":{".class":"TupleType","implicit":false,"items":["torch._tensor.Tensor","torch._tensor.Tensor"],"partial_fallback":{".class":"Instance","args":[{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.tuple"}},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"init_logger":{".class":"SymbolTableNode","cross_ref":"vllm.logger.init_logger","kind":"Gdef"},"is_flashmla_supported":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"FuncDef","abstract_status":0,"arg_kinds":[],"arg_names":[],"dataclass_transform_spec":null,"deprecated":null,"flags":[],"fullname":"vllm.attention.ops.flashmla.is_flashmla_supported","name":"is_flashmla_supported","type":{".class":"CallableType","arg_kinds":[],"arg_names":[],"arg_types":[],"bound_args":[],"def_extras":{"first_arg":null},"fallback":"builtins.function","from_concatenate":false,"implicit":false,"imprecise_arg_kinds":false,"is_ellipsis_args":false,"name":"is_flashmla_supported","ret_type":{".class":"TupleType","implicit":false,"items":["builtins.bool",{".class":"UnionType","items":["builtins.str",{".class":"NoneType"}],"uses_pep604_syntax":false}],"partial_fallback":{".class":"Instance","args":[{".class":"AnyType","missing_import_name":null,"source_any":null,"type_of_any":6}],"extra_attrs":null,"type_ref":"builtins.tuple"}},"type_guard":null,"type_is":null,"unpack_kwargs":false,"variables":[]}}},"logger":{".class":"SymbolTableNode","kind":"Gdef","node":{".class":"Var","flags":["is_inferred","has_explicit_value"],"fullname":"vllm.attention.ops.flashmla.logger","name":"logger","type":"vllm.logger._VllmLogger"}},"torch":{".class":"SymbolTableNode","cross_ref":"torch","kind":"Gdef"},"vllm":{".class":"SymbolTableNode","cross_ref":"vllm","kind":"Gdef"}},"path":"c:\\Users\\shivam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\vllm\\attention\\ops\\flashmla.py"}